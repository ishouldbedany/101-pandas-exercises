{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 75 pandas Exercises: Exercises 31 to 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises 31 to 40 from [here](https://www.machinelearningplus.com/python/101-pandas-exercises-python/). Each exercise includes the question, the input and the solution's code. Sometimes, alternative solutions and comments to better explain solutions/pandas functionality are offered.\n",
    "\n",
    "Requirements: \n",
    "+ `pandas`\n",
    "+ `numpy`\n",
    "\n",
    "Happy Pandasing! üêº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill an intermittent time series so all missing dates show up with values of previous non-missing date.** `ser` has missing dates and values. Make all missing dates appear and fill up with value from previous date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser = pd.Series([1,10,3,np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, two approaches (generate a new daily index starting on our first day and ending on the last, applying it with `pd.Series.reindex`), setting the new value as NaN and then doing NaN-filling by copying the previous value. Alternatively, we can resample our `pd.Series` and get one of them done for free. Let's try both and see that one of them is not like the others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the new index: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = pd.date_range(start=ser.index[0], end=ser.index[-1], freq='D') # D stands for daily frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reindexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-02     NaN\n",
      "2000-01-03    10.0\n",
      "2000-01-04     NaN\n",
      "2000-01-05     NaN\n",
      "2000-01-06     3.0\n",
      "2000-01-07     NaN\n",
      "2000-01-08     NaN\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser_reindex = ser.reindex(new_index, fill_value=np.nan)\n",
    "print(ser_reindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fill NaNs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-02     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-04    10.0\n",
      "2000-01-05    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-07     3.0\n",
      "2000-01-08     3.0\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser_fixed = ser_reindex.fillna(method='pad')  # pad is forward fill, equivalent to propagating valid values forward\n",
    "print(ser_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done. Let's try it the other way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-02     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-04    10.0\n",
      "2000-01-05    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-07     3.0\n",
      "2000-01-08     NaN\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser_fixed_alt = ser.resample(rule='D').pad() # resample to a daily frequency then call filling with a daily frequency\n",
    "print(ser_fixed_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, seems we need a final operation (the second to last value was a NaN, so forward propagation was not valid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-02     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-04    10.0\n",
      "2000-01-05    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-07     3.0\n",
      "2000-01-08     3.0\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ser_fixed_alt.fillna(method='pad', inplace=True)\n",
    "print(ser_fixed_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done. Quicker, _huh?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the autocorrelations of a numeric series.** Compute autocorrelations for the first 10 lags of `ser`. Find out which lag has the largest correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, `pandas` has built-in support for calculating the autocorrelation of a signal, which is just sliding two copies of the signal one over the other and computing the value of their convolution operation. Auto-correlation becomes particularly interesting when you can shift one time series `x` samples relative to the other (lagging one of them). `pandas` has support for that too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_values = np.arange(0, 10)\n",
    "auto_corr_vals = [ser.autocorr(lag=i) for i in lag_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the value of the autocorrelations (ignoring the first, has the signal will exactly equal to itself when there's no lag involved): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03755812497809473, -0.02109999814539558, 0.03181184882563077, -0.29807718748493656, -0.05921651437011084, 0.7923951272939062, 0.0012462196812533216, 0.2885403792390042, -0.1564077878210171]\n"
     ]
    }
   ],
   "source": [
    "print(auto_corr_vals[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lag value with the highest autocorrelation is 6.\n"
     ]
    }
   ],
   "source": [
    "print(\"The lag value with the highest autocorrelation is {}.\".format(np.argmax(auto_corr_vals[1:])+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import only every nth row from a csv file to create a dataframe.** Import every 50th row of the [Boston Housing](https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv) dataset as a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_link = 'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is in the `.csv` format and `pandas` has a very competent `pd.read_csv` method, so let's bet on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset_link, chunksize=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `chunksize` argument is used when we want to load big files (which won't fit into memory). It returns an iterator - not actual data, but directions of where to go when a certain chunk of the data is required. So, we now have these chunks of 50 rows of the dataset, and we are only interested in the first row. So, we progressively extract that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = pd.DataFrame() # empty dataframe to which we will be appending things\n",
    "\n",
    "for chunk in data: \n",
    "    data_filtered = data_filtered.append(chunk.iloc[0]) # we append all columns of the first row of the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>b</th>\n",
       "      <th>chas</th>\n",
       "      <th>crim</th>\n",
       "      <th>dis</th>\n",
       "      <th>indus</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "      <th>nox</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>rad</th>\n",
       "      <th>rm</th>\n",
       "      <th>tax</th>\n",
       "      <th>zn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>2.31</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.575</td>\n",
       "      <td>296.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>45.7</td>\n",
       "      <td>395.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08873</td>\n",
       "      <td>6.8147</td>\n",
       "      <td>5.64</td>\n",
       "      <td>13.45</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.439</td>\n",
       "      <td>16.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.963</td>\n",
       "      <td>243.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>79.9</td>\n",
       "      <td>394.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14866</td>\n",
       "      <td>2.7778</td>\n",
       "      <td>8.56</td>\n",
       "      <td>9.42</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.520</td>\n",
       "      <td>20.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.727</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>97.3</td>\n",
       "      <td>372.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.65660</td>\n",
       "      <td>1.6180</td>\n",
       "      <td>19.58</td>\n",
       "      <td>14.10</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.871</td>\n",
       "      <td>14.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.122</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>13.9</td>\n",
       "      <td>384.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01778</td>\n",
       "      <td>7.6534</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.45</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.403</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.135</td>\n",
       "      <td>402.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age       b  chas     crim     dis  indus  lstat  medv    nox  ptratio  \\\n",
       "0    65.2  396.90   0.0  0.00632  4.0900   2.31   4.98  24.0  0.538     15.3   \n",
       "50   45.7  395.56   0.0  0.08873  6.8147   5.64  13.45  19.7  0.439     16.8   \n",
       "100  79.9  394.76   0.0  0.14866  2.7778   8.56   9.42  27.5  0.520     20.9   \n",
       "150  97.3  372.80   0.0  1.65660  1.6180  19.58  14.10  21.5  0.871     14.7   \n",
       "200  13.9  384.30   0.0  0.01778  7.6534   1.47   4.45  32.9  0.403     17.0   \n",
       "\n",
       "     rad     rm    tax    zn  \n",
       "0    1.0  6.575  296.0  18.0  \n",
       "50   4.0  5.963  243.0  21.0  \n",
       "100  5.0  6.727  384.0   0.0  \n",
       "150  5.0  6.122  403.0   0.0  \n",
       "200  3.0  7.135  402.0  95.0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
