{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 75 pandas Exercises: Exercises 21 to 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises 21 to 30 from [here](https://www.machinelearningplus.com/python/101-pandas-exercises-python/). Each exercise includes the question, the input and the solution's code. Sometimes, alternative solutions and comments to better explain solutions/pandas functionality are offered.\n",
    "\n",
    "Requirements: \n",
    "+ `pandas`\n",
    "+ `numpy`\n",
    "\n",
    "Happy Pandasing! üêº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # required for some questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to convert a series of date-strings to a timeseries?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert this to a datetime format understood by Pandas, we would need to specify a format that the parser would identify (something alone the lines of DD-MM-YYYY). However, we have several different date formats in `ser`, so we would need multiple parsing specifications. Thankfully, Pandas already has a built-in parsing engine that can automatically extract dates from common timestamp formats.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ser = pd.to_datetime(ser, infer_datetime_format=True) # infer datetime format to activate the built-in parsing engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-01 00:00:00\n",
      "1   2011-02-02 00:00:00\n",
      "2   2012-03-03 00:00:00\n",
      "3   2013-04-04 00:00:00\n",
      "4   2014-05-05 00:00:00\n",
      "5   2015-06-06 12:20:00\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(new_ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All date strings converted to a common, continuous format, that can be easily used as a `DataFrame`'s  index.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the day of month, week number, day of year and day of week from a series of date strings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, and building upon exercise 22, let's convert everything to the `pd.Timestamp` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "ser_ts = pd.to_datetime(ser)\n",
    "print(type(ser_ts))\n",
    "print(type(ser_ts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-01 00:00:00\n",
      "1   2011-02-02 00:00:00\n",
      "2   2012-03-03 00:00:00\n",
      "3   2013-04-04 00:00:00\n",
      "4   2014-05-05 00:00:00\n",
      "5   2015-06-06 12:20:00\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(ser_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we know have a `pd.Series` of timestamps. The `pd.Timestamp` is a complex object holding, in its attributes, all the metadata we are looking for, so let's extract it with a bit of list comprehension magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_month = [ts.days_in_month for ts in ser_ts]\n",
    "week_number = [ts.weekofyear for ts in ser_ts]\n",
    "day_of_year = [ts.dayofyear for ts in ser_ts]\n",
    "day_of_week = [ts.day_name() for ts in ser_ts] # previously, it was weekday_name, but it's being phased out in favour of the method day_name().\n",
    "# It's a method because it has a locale argument (a same absolute timestamp can mean different week days, according to the timezone)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day in month: [31, 28, 31, 30, 31, 30]\n",
      "Week number: [53, 5, 9, 14, 19, 23]\n",
      "Day of the year: [1, 33, 63, 94, 125, 157]\n",
      "Weekday name: ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n"
     ]
    }
   ],
   "source": [
    "print(\"Day in month: {}\".format(day_of_month))\n",
    "print(\"Week number: {}\".format(week_number))\n",
    "print(\"Day of the year: {}\".format(day_of_year))\n",
    "print(\"Weekday name: {}\".format(day_of_week))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Voil√†!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert year-month string to dates corresponding to the 4th day of the month?** Change `ser` to dates that start with the 4th day of the respective months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so maybe we can go for a bit of timestamp arithmetic? Let's start by creating a timestamp `pd.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2010-01-01\n",
      "1   2011-02-01\n",
      "2   2012-03-01\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "ser_ts = pd.to_datetime(ser)\n",
    "print(ser_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we can implement timestamp arithmetic on `pd.Timestamps` objects using `pd.Timedelta` to create our time parcels and, well... arithmetic operators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-04\n",
       "1   2011-02-04\n",
       "2   2012-03-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_time = pd.Timedelta(days=3)\n",
    "ser_ts_delta = ser_ts + delta_time\n",
    "ser_ts_delta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Easy peasy!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter words that contain at least 2 vowels from a `pd.Series`?** From `ser`, extract the words containing at least 2 vowels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's count the vowels in each element of the `pd.Series` and filter based on that. The best way to count elements in a list (apart from mcgyvering it) is to use `collections.Counter`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pre-process the list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = list('aeiou') # quick & dirty way to transform a word into a list of characters\n",
    "ser_lower = ser.apply(lambda x: x.lower()) # putting things in lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's map each element in `ser` to its number of vowels. Calling `Counter()` on a string returns a dictionary with all the letters in that string and the number of occurrences of that letter. By accessing only the keys of that dictionary that are vowels and summing them up, we get the vowel count for each entry in `ser_lower`. \n",
    "\n",
    "**Note**: The `.get()` method of a dictionary allows setting a default value in case a key is not found. This is crucial because if the vowel we are sweeping for is not present in the word, it would error out. Instead, we set it to 0, meaning no vowel is present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "ser_vowels_count = ser_lower.map(lambda x: sum([Counter(x).get(v, 0) for v in vowels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the vowel counts in the `pd.Series` `ser_vowels_count`, let's filter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser[ser_vowels_count >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's done. Partly, based on the suggested solution. A little bit complex upon a first inspection because a lot is going on on that one-liner above, but hey!, learned about `collections.Counter`, a very useful tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter valid emails from a `pd.Series`**. Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input & regular expression pattern to detect valid emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import a regular expression processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just test every element of the series against the regular expression and extract the email in case there's a match: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']\n"
     ]
    }
   ],
   "source": [
    "is_mail = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "emails_only = emails[is_mail]\n",
    "print(emails_only.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution was shamelessly stolen from the suggested solution. I am starting to realize that applying the `map()` method and using a list comprehension are interchangeable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another of the suggested solutions is using the string representation of the series, againts which the regular expression processor can run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rameses@egypt.com'], ['matt@t.co'], ['narendra@modi.com']]\n"
     ]
    }
   ],
   "source": [
    "valid_emails_alt = emails.str.findall(pattern, flags=re.IGNORECASE)[1:] # the first element is an empty, so let's ignore it\n",
    "print(list(valid_emails_alt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this `pd.Series` is a complex nested object with an extra level of hierarchy, which we need to manually simplify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']\n"
     ]
    }
   ],
   "source": [
    "valid_emails_alt = [email[0] for email in valid_emails_alt]\n",
    "print(valid_emails_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Simplified it is._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the mean of a `pd.Series` grouped by another `pd.Series`.** Compute the mean of `weights` of each `fruit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's take a look at our lists: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    banana\n",
      "1    carrot\n",
      "2     apple\n",
      "3    banana\n",
      "4    carrot\n",
      "5    carrot\n",
      "6     apple\n",
      "7    carrot\n",
      "8    banana\n",
      "9     apple\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.0\n",
      "1     2.0\n",
      "2     3.0\n",
      "3     4.0\n",
      "4     5.0\n",
      "5     6.0\n",
      "6     7.0\n",
      "7     8.0\n",
      "8     9.0\n",
      "9    10.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the idea is to get all weights corresponding to a certain fruit and compute their average. Can we... `groupby` the value in `fruit`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.groupby.SeriesGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "grouped = weights.groupby(fruit)\n",
    "print(type(grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We now have a `pd.SeriesGroupBy` object, an agglomeration of groups upon which we can apply standard `pd.Series` operations, like getting the averages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple     6.666667\n",
      "banana    4.666667\n",
      "carrot    5.250000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "means = grouped.mean()\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We even get a `pd.Series` back indexed by the group's name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['apple', 'banana', 'carrot'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(means.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Niiiice!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the euclidean distance between two series?** Compute the euclidean distance between the points `pd.Series` `p` and `q`.\n",
    "The Euclidean distance is given by $\\sqrt{\\sum(p_{i} - q_{i})^{2}}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's be practical about it and praise the interoperability of `pd.Series` and `numpy`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.16590212458495\n"
     ]
    }
   ],
   "source": [
    "euclidean_dist = np.sum((p-q)**2)**0.5 # For extra readability, we could go for np.sqrt(np.sum((p-q)**2))\n",
    "print(euclidean_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find all the local maxima (or peaks) in a numeric series.** Get the positions of peaks (values surrounded by smaller values on both sides) in `ser`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is one exercise that doesn't really require all that much Pandasing and is easily solvable through `numpy`. We differentiate the array on both the forward and backwards direction and the indexes of the negative values in both directions will be our peaks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 7]\n"
     ]
    }
   ],
   "source": [
    "diff_forward = np.diff(ser)\n",
    "diff_backwards = np.diff(ser[::-1])\n",
    "peaks = np.intersect1d(np.where(diff_forward < 0)[0], np.where(diff_backwards < 0)[0])\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_A simple enough solution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace missing spaces in a string with the least frequent character.** Replace the spaces in `my_str` with the least frequent character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = 'dbc deb abed gade'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we first have to use Pandas to determine the least frequent character. Let's create a `pd.Series` with one character per row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     d\n",
      "1     b\n",
      "2     c\n",
      "3      \n",
      "4     d\n",
      "5     e\n",
      "6     b\n",
      "7      \n",
      "8     a\n",
      "9     b\n",
      "10    e\n",
      "11    d\n",
      "12     \n",
      "13    g\n",
      "14    a\n",
      "15    d\n",
      "16    e\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "str_series = pd.Series(data=[i for i in my_str])\n",
    "print(str_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to find the least frequent value, we use `pd.Series.value_counts()`, which returns us, for each unique value in the `pd.Series`, their occurrence count - a sort of an histogram ordered, by default, in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "     3\n",
      "b    3\n",
      "e    3\n",
      "a    2\n",
      "g    1\n",
      "c    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(str_series.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_freq = str_series.value_counts().index[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's replace all the empty spaces with this `least_freq` character (using the built-in `pd.Series.replace()` method) and convert the series back to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbccdebcabedcgade\n"
     ]
    }
   ],
   "source": [
    "replaced = str_series.replace(' ', value=least_freq).tolist()\n",
    "print(''.join(replaced)) # Simple trick to convert a list of characters into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Voil√°!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêº Exercise 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a `TimeSeries` starting at ‚Äò2000-01-01‚Äô with the following 10 weekends (saturdays), each day having as values a random number.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the first of January of 2000 was actually a Saturday, so first we just have to create a wekly `TimeSeries` starting that day and lasting for 10 weeks. This TimeSeries is going to be our index (indexing random values, in this case). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2000-01-01', '2000-01-08', '2000-01-15', '2000-01-22',\n",
      "               '2000-01-29', '2000-02-05', '2000-02-12', '2000-02-19',\n",
      "               '2000-02-26', '2000-03-04'],\n",
      "              dtype='datetime64[ns]', freq='W-SAT')\n"
     ]
    }
   ],
   "source": [
    "index_weeks = pd.date_range(start='2000-01-01', periods=10, freq = 'W-SAT')\n",
    "print(index_weeks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(the `freq` argument specifies that we want a weekly frequency starting at the closest saturday. The entire syntax is described [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just create a `pd.Series` with random data. A `pd.Series` indexed by `index_weeks`, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01    42\n",
      "2000-01-08    44\n",
      "2000-01-15    38\n",
      "2000-01-22    15\n",
      "2000-01-29    39\n",
      "2000-02-05    37\n",
      "2000-02-12    85\n",
      "2000-02-19    23\n",
      "2000-02-26    80\n",
      "2000-03-04    93\n",
      "Freq: W-SAT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dates_and_random = pd.Series(data=np.random.randint(low=0, high=100, size=len(index_weeks)), index=index_weeks)\n",
    "print(dates_and_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See ya next notebook! üêº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't stop? [Exercises 31 to 40](TODO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
